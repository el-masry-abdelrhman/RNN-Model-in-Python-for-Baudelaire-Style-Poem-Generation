{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **RNR for Baudelaire poem immitation**"
      ],
      "metadata": {
        "id": "oqlmeUPW8-re"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d2fwzXXcB_KI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8278406f-5803-404b-cd52-0ab47cec1e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "\n",
        "%pip install -q -U tensorflow-addons\n",
        "%pip install -q -U transformers\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n63dMA-ACFoF",
        "outputId": "e6587cfa-3cd3-4504-9f8a-3c53af0a1587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________________ Batch 0 \n",
            "X_batch\n",
            "[[6 7 8 9]\n",
            " [2 3 4 5]\n",
            " [4 5 6 7]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 7  8  9 10]\n",
            " [ 3  4  5  6]\n",
            " [ 5  6  7  8]]\n",
            "____________________ Batch 1 \n",
            "X_batch\n",
            "[[ 0  1  2  3]\n",
            " [ 8  9 10 11]\n",
            " [10 11 12 13]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 1  2  3  4]\n",
            " [ 9 10 11 12]\n",
            " [11 12 13 14]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "n_steps = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
        "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
        "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
        "dataset = dataset.batch(3).prefetch(1)\n",
        "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
        "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
        "    print(X_batch.numpy())\n",
        "    print(\"=\" * 5, \"\\nY_batch\")\n",
        "    print(Y_batch.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Importation**"
      ],
      "metadata": {
        "id": "z13Nj5vv9zfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDTi5E4oCt5O"
      },
      "outputs": [],
      "source": [
        "with open('Les_fleurs_du_mal_Baudelaire.txt', 'r', encoding='utf-8') as fichier:\n",
        "    # Lire le contenu du fichier\n",
        "    Baudelaire_text = fichier.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcAx20mpCxL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c7ed0a-992a-4713-e8bf-1e2d9d12db1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La sottise, l’erreur, le péché, la lésine,\n",
            "Occupent nos esprits et travaillent nos corps,\n",
            "Et nous alimentons nos aimables remords,\n",
            "Comme les mendian\n"
          ]
        }
      ],
      "source": [
        "print(Baudelaire_text[:148])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRVC1OTWCzO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c7512575-3366-4178-f0a4-37d898fdeb43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !(),-.:;?abcdefghijklmnopqrstuvwxyz«»àâæçèéêëîïôùûüœ—’…'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\".join(sorted(set(Baudelaire_text.lower())))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We encode each character**"
      ],
      "metadata": {
        "id": "rn0BmItb_CgH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVxXwcZDC1Wa"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(Baudelaire_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGjPs0SVC4Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5d3d3e-3366-4cc3-a8d4-ce003aff9d08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 22, 12, 2, 10, 5, 24, 13, 4, 6, 1, 2, 10, 1, 13, 4, 3, 5, 33]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "test = tokenizer.texts_to_sequences([\"Abdelrhman El Masry\"])\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkIOLFfcC-WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f36c7f-f453-4a0d-9767-dc9b9cb632c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a b d e l r h m a n   e l   m a s r y']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgstCjMaDEiB"
      },
      "outputs": [],
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now try to find the next character of each sequences of 100 characters"
      ],
      "metadata": {
        "id": "v8YrEcYIA2kr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGr-Vab5DG5L"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([Baudelaire_text])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "test_data = tf.data.Dataset.from_tensor_slices(encoded[train_size:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8nYbxMWDJGx"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "test_data = test_data.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReWYg40vDLqo"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "test_data = test_data.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R5KoBPGDNsY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6GNwXZsDP85"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(100000).batch(batch_size)\n",
        "test_data = test_data.shuffle(100000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "test_data = test_data.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnqADyAxDSM4"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "\n",
        "test_data = test_data.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqfd_v4FDUds"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.prefetch(1)\n",
        "test_data = test_data.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCBGNUy8DWOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf7416a-4fbd-43c8-f643-b70a2fc1aea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 57) (32, 100)\n"
          ]
        }
      ],
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model training**"
      ],
      "metadata": {
        "id": "0y66Uzf9BCD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7eblRA7DZeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566323f0-e775-49df-dad9-cad3f2335646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3946/3946 [==============================] - 80s 12ms/step - loss: 1.9906 - accuracy: 0.3958\n",
            "Epoch 2/10\n",
            "3946/3946 [==============================] - 69s 13ms/step - loss: 1.7363 - accuracy: 0.4603\n",
            "Epoch 3/10\n",
            "3946/3946 [==============================] - 67s 12ms/step - loss: 1.6704 - accuracy: 0.4774\n",
            "Epoch 4/10\n",
            "3946/3946 [==============================] - 67s 12ms/step - loss: 1.6337 - accuracy: 0.4872\n",
            "Epoch 5/10\n",
            "3946/3946 [==============================] - 67s 12ms/step - loss: 1.6085 - accuracy: 0.4938\n",
            "Epoch 6/10\n",
            "3946/3946 [==============================] - 68s 13ms/step - loss: 1.5904 - accuracy: 0.4984\n",
            "Epoch 7/10\n",
            "3946/3946 [==============================] - 66s 12ms/step - loss: 1.5765 - accuracy: 0.5022\n",
            "Epoch 8/10\n",
            "3946/3946 [==============================] - 66s 12ms/step - loss: 1.5656 - accuracy: 0.5052\n",
            "Epoch 9/10\n",
            "3946/3946 [==============================] - 65s 12ms/step - loss: 1.5559 - accuracy: 0.5077\n",
            "Epoch 10/10\n",
            "3946/3946 [==============================] - 65s 12ms/step - loss: 1.5476 - accuracy: 0.5101\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "history = model.fit(dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test of the model**"
      ],
      "metadata": {
        "id": "5yJOEEhABHWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "pRMmM8wVBq0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc4e34e-8c94-416f-c8aa-dae285e56bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436/436 [==============================] - 6s 7ms/step - loss: 1.6362 - accuracy: 0.5027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "metadata": {
        "id": "JhhSFsOSIwcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_new = preprocess([\"fleu\"])\n",
        "#Y_pred = model.predict_classes(X_new)\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ],
      "metadata": {
        "id": "DUwhPgvHI0kl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9364c050-329a-44b2-80ad-1fbf8a7a88d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
      ],
      "metadata": {
        "id": "88QYxXrSI263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a822ff7d-e513-4015-9f2a-00e2d689988f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Poem creation using our model**"
      ],
      "metadata": {
        "id": "6FOmFSEsC1O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "ErFLaZnCI5Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "next_char(\"étoil\", temperature=0.2)"
      ],
      "metadata": {
        "id": "Yl-6IlqhI7ib",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "65312399-55ff-4725-ec9f-210db0a89200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def complete_text(text, n_chars=400, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "3iIuh3HTI9aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"Les fleurs\", temperature=0.2))"
      ],
      "metadata": {
        "id": "uJ7nkbOhJE7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae0da2b-10f9-47a4-9c8e-cedd90321b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les fleurs et des soleils marches,\n",
            "des chats pleins de larmes,\n",
            "et les parfums de la paresse et de la main de l’antique fleurir de l’antique souvent,\n",
            "et des cœurs mortels et de sourir le cour de la carieuse,\n",
            "et les cours et des fleurs et des fleurs et des fleurs,\n",
            "et les charmes sont pleins de la vie et de la vie et de la chair ;\n",
            "le soleil de la vie et le courage et la bouche infini de la carieuse,\n",
            "au fond d’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"Les fleurs\", temperature=0.5))"
      ],
      "metadata": {
        "id": "RaGRsxAuJ4PF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995b4a72-bba7-492a-90a6-be2b8df9affc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les fleurs en la forme de ton âme se mire ;\n",
            "et de voir moi, même pour l’adire,\n",
            "la fond de la volupté de la douleur au siaistre,\n",
            "je veux par l’air et les pieds d’amour de l’azur et de la race de ces vines\n",
            "d’un grand passion et l’air de mon cœur sont les ailes riches ;\n",
            "ainsi qu’une foute du chat on ne secret.\n",
            "c’est un cammenu par le navire\n",
            "dans les palmes,\n",
            "et par le flot de la taille parfumé d’un rayon sonfer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"Les fleurs\", temperature=0.7))"
      ],
      "metadata": {
        "id": "CERYXpOYJvhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef30a536-3af2-4f2a-d315-b6119c263aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les fleurs, ces bras soir, ton cour sombre et l’azur, marguerait l’œil clair immonde.\n",
            "je veux te regard minci notre hater\n",
            "et divent qu’en ma vent\n",
            "dont l’odeur de la couleur\n",
            "de dans le ciel, où la pason soit des rêves\n",
            "de penserr tu de l’hémal\n",
            "de sa chair léconde où la satité de pitié !\n",
            "je veux par ses pitiés froisses d’ordre,\n",
            "et les désarts de noir le rémons)\n",
            "ainsi pourtur et la dévoté de conterses,\n",
            "ta tête \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}